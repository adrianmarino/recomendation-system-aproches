{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation systems: Deep Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is made up of feature layers that have users, movies and movie genres embedings followed by a neural network with dense layers and finally one output that is the rating prediction that input user(id) could assign to input movie(id)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inputs**\n",
    "* **User id**: Really this is traducet as a sequence because embedding layers only can manage sequenced identifiers.\n",
    "* **Movie id**: Idem to User id.\n",
    "* **Movie genres**: One column by genre.\n",
    "\n",
    "**Output**\n",
    "*  **Rating prediction** that user could assign to movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Links**\n",
    "* [Deep Learning With Keras: Recommender Systems](https://www.johnwittenauer.net/deep-learning-with-keras-recommender-systems/)\n",
    "* [Collaborative Filtering for Movie Recommendations](https://keras.io/examples/structured_data/collaborative_filtering_movielens/)\n",
    "* [Movie lens datasets](https://grouplens.org/datasets/movielens/)\n",
    "* [Recommendation Systems Benchmarks](https://paperswithcode.com/task/recommendation-systems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from util import tf_detected_devices, tf_version, plot_model, Config, LoggerFactory, create_path\n",
    "from callback import MetricsPlotter\n",
    "from data import DataFrameDataGenerator\n",
    "from recommendation import UserMovieGenderEmbeddingDenseModelFactory, RecommendationsDataGenerator\n",
    "from spark import SparkSessionFactory, read_csv, column_values, train_test_split, PageSet, get_columns, get_rows\n",
    "\n",
    "import pyspark.sql.types as t\n",
    "import pyspark.sql as s\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logger config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RootLogger root (INFO)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config(path='../config/config.yaml')\n",
    "LoggerFactory(config['logger']).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup test_mode variable to enable or disable model train before check their prediction precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Make sure that nvidia driver is installed runing next command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce RTX 3080, 10015 MiB\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi --query-gpu=gpu_name,memory.total --format=csv | sed -n 2p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If this shows a GPU model and memory size, that's all right, otherwise make suze that has the nvidia driver installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Let's check tensorflow version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tensorflow version: 2.5.0-dev20210106'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_version()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: Let's check devices that tensorflow detect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Device Type</th>\n",
       "      <th>Memory</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/device:CPU:0</td>\n",
       "      <td>CPU</td>\n",
       "      <td>256M</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/device:GPU:0</td>\n",
       "      <td>GPU</td>\n",
       "      <td>7G</td>\n",
       "      <td>device: 0, name: GeForce RTX 3080, pci bus id:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name Device Type Memory  \\\n",
       "0  /device:CPU:0         CPU   256M   \n",
       "1  /device:GPU:0         GPU     7G   \n",
       "\n",
       "                                         Description  \n",
       "0                                                     \n",
       "1  device: 0, name: GeForce RTX 3080, pci bus id:...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_detected_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4**: Make sure that tensorflow detect cuda libs and GPU devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare model input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Create a predefined spark session. this is used to create a pipeline that build the model input features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://skynet.local:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>recommendations</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fbbb00f44c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = SparkSessionFactory.create()\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.driver.memory', '3G'),\n",
       " ('spark.driver.host', 'skynet.local'),\n",
       " ('spark.driver.port', '45893'),\n",
       " ('spark.executor.instances', '12'),\n",
       " ('spark.executor.memory', '2G'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.app.name', 'recommendations'),\n",
       " ('spark.app.id', 'local-1610904657936'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: When create a spark session this run a new spark cluster with one instance in localhost. You can monitor instance jobs clicking the **Spark UI** link. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Load raw dataset to a spark dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP_PATH = './temp'\n",
    "TRAIN_PATH = f'{TEMP_PATH}/train'\n",
    "VAL_PATH = f'{TEMP_PATH}/val'\n",
    "TEST_PATH = f'{TEMP_PATH}/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = read_csv(session, f'{TRAIN_PATH}/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = read_csv(session, f'{VAL_PATH}/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = read_csv(session, f'{TEST_PATH}/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 17,495,983 samples.\n",
      "Validation set size: 6,753,465 samples.\n"
     ]
    }
   ],
   "source": [
    "print(f'Train set size: {\"{:,}\".format(train_set.count())} samples.')\n",
    "print(f'Validation set size: {\"{:,}\".format(val_set.count())} samples.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Let's see min and max value of rating column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratting - min:  0.5 max: 5.0\n"
     ]
    }
   ],
   "source": [
    "min_max = train_set.agg(f.min('rating'), f.max('rating')).collect()[0]\n",
    "min_rating, max_rating = min_max[0], min_max[1]\n",
    "\n",
    "print('Ratting - min: ', min_rating, 'max:', max_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Let's see all dataset columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnService:\n",
    "    def __init__(self, columns):\n",
    "        excluded_columns = ['user_id', 'movie_id']\n",
    "        self.labels = ['rating']\n",
    "\n",
    "        self.features = list(set(columns) - set(self.labels) - set(excluded_columns))\n",
    "        self.features = sorted(self.features, key=lambda x: 'gen_' in x)\n",
    "\n",
    "        self.gender_features = [c for c in self.features if 'gen_' in c]\n",
    "        self.emb_features = [c for c in self.features if '_seq' in c]\n",
    "        self.emb_features = sorted(self.emb_features, key=lambda x: 'user' in x, reverse=True)\n",
    "\n",
    "column_manager = ColumnService(train_set.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5**: Calculate train, val batch_size and plot interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "steps  = 2000\n",
    "epochs = 5\n",
    "plot_interval = math.floor(steps / 10)\n",
    "\n",
    "train_batch_size        = math.floor(train_set.count() / steps)\n",
    "val_batch_size    = math.floor(val_set.count() / steps)\n",
    "evaluate_interval = plot_interval + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Batch Size      : 8,747.\n",
      "Validation Batch Size : 3,376.\n",
      "Plot Interval         : 200\n",
      "Evaluate Interval     : 201\n",
      "Epochs                : 5\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Batch Size      : {\"{:,}\".format(train_batch_size)}.')\n",
    "print(f'Validation Batch Size : {\"{:,}\".format(val_batch_size)}.')\n",
    "print('Plot Interval         :', plot_interval)\n",
    "print('Evaluate Interval     :', evaluate_interval)\n",
    "print('Epochs                :', epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 2021-01-17 14:31:17 - page-set-140444089444336 - Page Size: 8747\n",
      "INFO 2021-01-17 14:31:17 - page-set-140444089444336 - Pages Count: 2001\n",
      "INFO 2021-01-17 14:31:17 - page-set-140444089444336 - Total elements: 17495983\n"
     ]
    }
   ],
   "source": [
    "train_generator = RecommendationsDataGenerator(\n",
    "    train_set,\n",
    "    train_batch_size,\n",
    "    column_manager,\n",
    "    shuffle=True,\n",
    "    name='train'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 2021-01-17 14:31:17 - Profiler - Desc: 'Get page' - Time: 6 ms\n",
      "INFO 2021-01-17 14:32:03 - Profiler - Desc: 'Resolve users embedding' - Time: 16579 ms\n",
      "INFO 2021-01-17 14:32:18 - Profiler - Desc: 'Resolve movies embedding' - Time: 15146 ms\n",
      "INFO 2021-01-17 14:33:00 - Profiler - Desc: 'Resolve genders one-hot array' - Time: 41431 ms\n",
      "INFO 2021-01-17 14:33:00 - Profiler - Desc: 'Resolve features' - Time: 73158 ms\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'logger'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-35d3089c92ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/development/machine-learning/recommendations/src/data/generator/data_frame/data_frame_data_generatror.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mProfiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Resolve features'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprofiler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__feature_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Size: {len(X)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mProfiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Resolve labels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'logger'"
     ]
    }
   ],
   "source": [
    "page = train_generator[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_generator = RecommendationsDataGenerator(\n",
    "    val_set,\n",
    "    val_batch_size,\n",
    "    column_manager,\n",
    "    shuffle=False,\n",
    "    name='val'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = train_set.select('user_seq') \\\n",
    "            .union(val_set.select('user_seq')) \\\n",
    "            .union(test_set.select('user_seq')) \\\n",
    "            .distinct() \\\n",
    "            .count()\n",
    "\n",
    "n_movies = train_set.select('movie_seq') \\\n",
    "            .union(val_set.select('movie_seq')) \\\n",
    "            .union(test_set.select('movie_seq')) \\\n",
    "            .distinct() \\\n",
    "            .count()\n",
    "\n",
    "print(f'Train set size: {\"{:,}\".format(n_users)}.')\n",
    "print(f'Validation set size: {\"{:,}\".format(n_movies)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UserMovieGenderEmbeddingDenseModelFactory.create(\n",
    "    n_users, \n",
    "    n_movies,\n",
    "    n_genders=len(column_manager.gender_features),\n",
    "    min_rating=min_rating, \n",
    "    max_rating=max_rating,\n",
    "    user_n_min_factors=50,\n",
    "    movie_n_min_factors=50,\n",
    "    lr=0.001,\n",
    "    units=[512],\n",
    "    dropout=[0.1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, rankdir=\"TB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    history = model.fit_generator(\n",
    "        generator=train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=epochs,\n",
    "        verbose=1, \n",
    "        callbacks=[\n",
    "            MetricsPlotter(\n",
    "                validation_generator=val_generator, \n",
    "                metrics_names=['loss'],\n",
    "                plot_interval=plot_interval,\n",
    "                evaluate_interval=evaluate_interval,\n",
    "                batch_size=train_batch_size,\n",
    "                val_batch_size=val_batch_size\n",
    "            )\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check model loss after training process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_xy_model(model, column_manager, data_frame, batch_size):\n",
    "    data_generator = RecommendationsDataGenerator(\n",
    "        data_frame,\n",
    "        column_manager.features,\n",
    "        column_manager.labels,\n",
    "        data_frame.count(),\n",
    "        shuffle=False\n",
    "    )\n",
    "    X, y = data_generator[0]\n",
    "    return model.evaluate(X, y, batch_size=batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = evaluate_xy_model(model, column_manager, val_set, val_batch_size)\n",
    "val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the weights tthat model has learned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WEIGHTS_PATH = create_path(f'../weights')\n",
    "WEIGHTS_FILE = f'{WEIGHTS_PATH}/user_movie_genders_deep_model_weights_val_loss_{val_loss}.h5'\n",
    "model.save_weights(WEIGHTS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
