{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation systems: Deep Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is made up of feature layers that have users, movies and movie genres embedings followed by a neural network with dense layers and finally one output that is the rating prediction that input user(id) could assign to input movie(id)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inputs**\n",
    "* **User id**: Really this is traducet as a sequence because embedding layers only can manage sequenced identifiers.\n",
    "* **Movie id**: Idem to User id.\n",
    "* **Movie genres**: One column by genre.\n",
    "\n",
    "**Output**\n",
    "*  **Rating prediction** that user could assign to movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Links**\n",
    "* [Deep Learning With Keras: Recommender Systems](https://www.johnwittenauer.net/deep-learning-with-keras-recommender-systems/)\n",
    "* [Collaborative Filtering for Movie Recommendations](https://keras.io/examples/structured_data/collaborative_filtering_movielens/)\n",
    "* [Movie lens datasets](https://grouplens.org/datasets/movielens/)\n",
    "* [Recommendation Systems Benchmarks](https://paperswithcode.com/task/recommendation-systems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import os\n",
    "from util import create_path, remove_dir\n",
    "\n",
    "def show_env_var(varname):\n",
    "    if varname in os.environ:\n",
    "        print(f'{varname}: {os.environ[varname]}')\n",
    "    else:\n",
    "        print(f'{varname} undefined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ray = False\n",
    "\n",
    "if user_ray:    \n",
    "    show_env_var('MODIN_OUT_OF_CORE')\n",
    "    show_env_var('MODIN_MEMORY')\n",
    "    show_env_var('MODIN_ON_RAY_PLASMA_DIR')\n",
    "\n",
    "    create_path(os.environ['MODIN_ON_RAY_PLASMA_DIR'])\n",
    "\n",
    "    import ray\n",
    "    import modin\n",
    "    import modin.pandas as pd\n",
    "    \n",
    "    modin.__version__\n",
    "\n",
    "    # ray.shutdown()\n",
    "    if not ray.is_initialized():\n",
    "        ray.init(num_cpus=24, num_gpus=1, dashboard_host=\"0.0.0.0\", dashboard_port=8080)\n",
    "    else:\n",
    "        print('Ray is already active!')\n",
    "else:\n",
    "    import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import keras_tuner as kt\n",
    "from util import tf_detected_devices, tf_version, plot_model, Config, LoggerFactory, create_path\n",
    "\n",
    "from callback import MetricsPlotter\n",
    "from data import InMemoryXyDataGenerator\n",
    "from recommendation import UserMovieGenderEmbeddingDenseModelFactory\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "from data import MovieLensDataSource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENDER_COLUMNS = [\n",
    "    'gen_film_noir', \n",
    "    'gen_none', \n",
    "    'gen_imax', \n",
    "    'gen_documentary',\n",
    "    'gen_romance', \n",
    "    'gen_drama', \n",
    "    'gen_adventure', \n",
    "    'gen_western',\n",
    "    'gen_animation',\n",
    "    'gen_mystery', \n",
    "    'gen_fantasy',\n",
    "    'gen_action', \n",
    "    'gen_comedy', \n",
    "    'gen_sci_fi', \n",
    "    'gen_musical',\n",
    "    'gen_war', \n",
    "    'gen_crime', \n",
    "    'gen_children', \n",
    "    'gen_horror', \n",
    "    'gen_thriller'\n",
    "]\n",
    "X_COLUMNS = ['user_seq', 'movie_seq'] + GENDER_COLUMNS\n",
    "Y_COLUMNS = ['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_counts(train_set, val_set, test_set):\n",
    "    logging.info(f'Train set count = {train_set.shape[0]} observations.')\n",
    "    logging.info(f'Validation set count = {val_set.shape[0]} observations.')\n",
    "    logging.info(f'Test set count = {test_set.shape[0]} observations.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, samples, batch_size):\n",
    "    X, y = samples[X_COLUMNS].values, samples[Y_COLUMNS].values\n",
    "    \n",
    "    generator = InMemoryXyDataGenerator(\n",
    "        X,\n",
    "        y, \n",
    "        batch_size,\n",
    "        shuffle=True, \n",
    "        to_input=to_input\n",
    "    )\n",
    "    X_batch, y_batch = generator[0]\n",
    "    \n",
    "    return model.evaluate(X_batch, y_batch, batch_size=batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_hyperparameters(tuner):\n",
    "    return tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "def create_best_model_from(tuner):\n",
    "    return tuner.hypermodel.build(get_best_hyperparameters(tuner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowest_loss_epoch(val_loss_per_epoch):\n",
    "    return val_loss_per_epoch.index(min(val_loss_per_epoch)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(losses, xlabel='Epoch', ylabel='Loss', title='Loss by epoch'):\n",
    "    plt.plot(list(range(1, len(losses)+1)), losses)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, observations):\n",
    "        self.observations = observations\n",
    " \n",
    "    def search_by_seqs(self, user_seq, movie_seq): \n",
    "        return self.observations[(self.observations.user_seq == user_seq) & (self.observations.movie_seq == movie_seq)]\n",
    "\n",
    "    def random_observation(self,  has_rating=True):\n",
    "        \"\"\"\n",
    "        Get a random observation.\n",
    "        \"\"\"\n",
    "        finish = True\n",
    "        while finish:\n",
    "            user_seq  = random.choice(self.observations['user_seq'])\n",
    "            movie_seq = random.choice(self.observations['movie_seq'])\n",
    "        \n",
    "            sample = self.search_by_seqs(user_seq, movie_seq)\n",
    "    \n",
    "            finish = sample.empty if has_rating else not sample.empty\n",
    "\n",
    "        return sample.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, samples, batch_size):\n",
    "    X = samples[X_COLUMNS].values\n",
    "    y = samples[Y_COLUMNS].values\n",
    " \n",
    "    generator = InMemoryXyDataGenerator(\n",
    "        X,\n",
    "        y, \n",
    "        batch_size,\n",
    "        shuffle=True, \n",
    "        to_input=to_input\n",
    "    )\n",
    "    X_batch, y_batch = generator[0]\n",
    "\n",
    "    y_predicted = model.predict(X_batch, batch_size=batch_size, verbose=0)\n",
    "\n",
    "    result = samples.copy()\n",
    "    result.insert(0, 'pred_rating', y_predicted) \n",
    "    return result \n",
    "\n",
    "def to_percent(value): return round(value * 100, 2)\n",
    "\n",
    "def get_metrics(\n",
    "    dataset,\n",
    "    max_error   = 1, \n",
    "    sample_size = 1000,\n",
    "    loss_fn     = lambda y_pred, y_true : abs(y_pred - y_true)\n",
    "):\n",
    "    true_positives = false_positives = 0\n",
    "    error_dits     = []\n",
    "\n",
    "    for index in range(0, sample_size):\n",
    "        observation = dataset.random_observation()\n",
    "\n",
    "        prediction = predict(model, observation, batch_size=observation.shape[0])\n",
    "\n",
    "        y_pred = prediction['pred_rating'].item()\n",
    "        y_true = prediction['rating'].item()\n",
    "\n",
    "        error = loss_fn(y_pred, y_true)\n",
    "        error_dits.append(error)\n",
    "\n",
    "        if  error <= max_error:\n",
    "            true_positives  +=1\n",
    "        else:\n",
    "            false_positives +=1\n",
    "\n",
    "    return {\n",
    "        'true_positives':  f'{to_percent(true_positives / sample_size)}%',\n",
    "        'false_positives': f'{to_percent(false_positives / sample_size)}%',\n",
    "        'error_dist':      error_dits\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logger config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RootLogger root (INFO)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config(path='../config/config.yaml')\n",
    "LoggerFactory(config['logger']).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Make sure that nvidia driver is installed runing next command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3080, 10240 MiB\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi --query-gpu=gpu_name,memory.total --format=csv | sed -n 2p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If this shows a GPU model and memory size, that's all right, otherwise make suze that has the nvidia driver installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Let's check tensorflow version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tensorflow version: 2.8.0'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_version()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: Let's check devices that tensorflow detect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Device Type</th>\n",
       "      <th>Memory</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/device:CPU:0</td>\n",
       "      <td>CPU</td>\n",
       "      <td>256M</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/device:GPU:0</td>\n",
       "      <td>GPU</td>\n",
       "      <td>6G</td>\n",
       "      <td>device: 0, name: NVIDIA GeForce RTX 3080, pci ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name Device Type Memory  \\\n",
       "0  /device:CPU:0         CPU   256M   \n",
       "1  /device:GPU:0         GPU     6G   \n",
       "\n",
       "                                         Description  \n",
       "0                                                     \n",
       "1  device: 0, name: NVIDIA GeForce RTX 3080, pci ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_detected_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4**: Make sure that tensorflow detect cuda libs and GPU devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare model input data\n",
    "\n",
    "**Step 1**: Load train, val and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP_PATH = './temp'\n",
    "TRAIN_PATH = f'{TEMP_PATH}/train'\n",
    "VAL_PATH = f'{TEMP_PATH}/val'\n",
    "TEST_PATH = f'{TEMP_PATH}/test'\n",
    "\n",
    "train  = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def read_csv(path):\n",
    "    all_files = glob.glob(path)\n",
    "    li = [pd.read_csv(filename, index_col=None, header=0) for filename in all_files]\n",
    "    return pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-27 01:15:56 INFO Train set count = 70288 observations.\n",
      "2022-02-27 01:15:56 INFO Validation set count = 20198 observations.\n",
      "2022-02-27 01:15:56 INFO Test set count = 8851 observations.\n"
     ]
    }
   ],
   "source": [
    "train_set = read_csv(f'{TRAIN_PATH}/*.csv')\n",
    "val_set   = read_csv(f'{VAL_PATH}/*.csv')\n",
    "test_set  = read_csv(f'{TEST_PATH}/*.csv')\n",
    "\n",
    "log_counts(train_set, val_set, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Let's see min and max value of rating column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-27 01:15:56 INFO Rattings:\n",
      " - min = 0.5\n",
      " - max = 5.0\n"
     ]
    }
   ],
   "source": [
    "min_rating, max_rating = train_set['rating'].min(), train_set['rating'].max()\n",
    "\n",
    "logging.info(f'Rattings:\\n - min = {min_rating}\\n - max = {max_rating}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Calculate train and val batch size and plot interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-27 01:15:56 INFO Steps: 100, Epochs: 80.\n",
      "2022-02-27 01:15:56 INFO Batch Size = (Train:702, Val:201).\n",
      "2022-02-27 01:15:56 INFO Interval = (Plot:50, Evaluate:51).\n"
     ]
    }
   ],
   "source": [
    "steps             = 100\n",
    "epochs            = 80\n",
    "plot_interval     = math.floor(steps / 2)\n",
    "\n",
    "train_batch_size  = math.floor(train_set.shape[0] / steps)\n",
    "val_batch_size    = math.floor(val_set.shape[0] / steps)\n",
    "evaluate_interval = plot_interval + 1\n",
    "\n",
    "logging.info(f'Steps: {steps}, Epochs: {epochs}.')\n",
    "logging.info(f'Batch Size = (Train:{train_batch_size}, Val:{val_batch_size}).')\n",
    "logging.info(f'Interval = (Plot:{plot_interval}, Evaluate:{evaluate_interval}).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_set**Step 4:** build tran, validation and test matrix, excluding ids for inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENDER_COLUMNS = [\n",
    "    'gen_film_noir', \n",
    "    'gen_none', \n",
    "    'gen_imax', \n",
    "    'gen_documentary',\n",
    "    'gen_romance', \n",
    "    'gen_drama', \n",
    "    'gen_adventure', \n",
    "    'gen_western',\n",
    "    'gen_animation',\n",
    "    'gen_mystery', \n",
    "    'gen_fantasy',\n",
    "    'gen_action', \n",
    "    'gen_comedy', \n",
    "    'gen_sci_fi', \n",
    "    'gen_musical',\n",
    "    'gen_war', \n",
    "    'gen_crime', \n",
    "    'gen_children', \n",
    "    'gen_horror', \n",
    "    'gen_thriller'\n",
    "]\n",
    "X_COLUMNS = ['user_seq', 'movie_seq'] + GENDER_COLUMNS\n",
    "Y_COLUMNS = ['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set[X_COLUMNS].values\n",
    "y_train = train_set[Y_COLUMNS].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = val_set[X_COLUMNS].values\n",
    "y_val = val_set[Y_COLUMNS].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_set[X_COLUMNS].values\n",
    "y_test = test_set[Y_COLUMNS].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5:** Define data generator. A data generator is used to provide next observations batch to model under training process both to forward pass and also to get a validation batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_input(X, y): return [X[:, 0],  X[:, 1], X[:, 2:22]], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = InMemoryXyDataGenerator(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    train_batch_size,\n",
    "    shuffle  = True,\n",
    "    to_input = to_input\n",
    ")\n",
    "\n",
    "val_generator = InMemoryXyDataGenerator(\n",
    "    X_val, \n",
    "    y_val, \n",
    "    val_batch_size, \n",
    "    shuffle  = True,\n",
    "    to_input = to_input\n",
    ")\n",
    "\n",
    "test_generator = InMemoryXyDataGenerator(\n",
    "    X_test, \n",
    "    y_test, \n",
    "    train_batch_size, \n",
    "    shuffle  = True,\n",
    "    to_input = to_input\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check train batch shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-27 01:15:56 INFO Train Batch columns: Users: (702,), Movies: (702,), genders:(702, 20)\n"
     ]
    }
   ],
   "source": [
    "batch = train_generator[0]\n",
    "\n",
    "logging.info(f'Train Batch columns: Users: {batch[0][0].shape}, Movies: {batch[0][1].shape}, genders:{batch[0][2].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-27 01:15:56 INFO user_seq: 250\n",
      "2022-02-27 01:15:56 INFO movie_seq: 567\n",
      "2022-02-27 01:15:56 INFO genders: [0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "logging.info(f'user_seq: {batch[0][0][0]}')\n",
    "logging.info(f'movie_seq: {batch[0][1][0]}')\n",
    "logging.info(f'genders: {batch[0][2][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check users/movies sequence count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "610"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids = set(np.concatenate((\n",
    "    train_set['user_id'].values,\n",
    "    val_set['user_id'].values,\n",
    "    test_set['user_id'].values\n",
    "), axis=0))\n",
    "\n",
    "n_users = len(user_ids)\n",
    "n_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8454"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_ids = set(np.concatenate((\n",
    "    train_set['movie_id'].values, \n",
    "    val_set['movie_id'].values,\n",
    "    test_set['movie_id'].values\n",
    "), axis=0))\n",
    "\n",
    "n_movies = len(movie_ids)\n",
    "n_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metrics_callback():\n",
    "    return MetricsPlotter(\n",
    "        validation_generator = val_generator, \n",
    "        metrics_names        = ['loss'],\n",
    "        plot_interval        = plot_interval,\n",
    "        evaluate_interval    = evaluate_interval,\n",
    "        batch_size           = train_batch_size,\n",
    "        val_batch_size       = val_batch_size\n",
    "    )\n",
    "\n",
    "def create_checkpoints_callback():\n",
    "    checkpoint_file = \\\n",
    "        create_path('./checkpoints') + \\\n",
    "        '/weights.epoch_{epoch:02d}-loss_{loss:.3f}-val_loss_{val_loss:.3f}.hdf5'\n",
    "\n",
    "    return ModelCheckpoint(\n",
    "        filepath          = checkpoint_file,\n",
    "        save_weights_only = True,\n",
    "        monitor           = 'val_loss',\n",
    "        mode              = 'max',\n",
    "        save_best_only    = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):  \n",
    "    # Hyperparameters\n",
    "    lr       = hp.Choice('lr', values=[0.01, 0.001, 0.001])\n",
    "\n",
    "    units1   = hp.Int('units1', min_value=10, max_value=300, step=10)  \n",
    "    dropout1 = hp.Float('dropout1', min_value=0.1, max_value=0.9, step=0.1)\n",
    "\n",
    "    units2   = hp.Int('units2', min_value=10, max_value=300, step=10)\n",
    "    dropout2 = hp.Float('dropout2', min_value=0.1, max_value=0.9, step=0.1)\n",
    "      \n",
    "    units3   = hp.Int('units3', min_value=10, max_value=300, step=10)\n",
    "    dropout3 = hp.Float('dropout3', min_value=0.1, max_value=0.9, step=0.1)\n",
    "\n",
    "    user_embeding_vector_size  = hp.Int(\n",
    "      'usersfactor', min_value=50, max_value=500, step=50\n",
    "    )\n",
    "    movie_embeding_vector_size = hp.Int(\n",
    "      'moviesfactor', min_value=50, max_value=500, step=50\n",
    "    )\n",
    "\n",
    "    return UserMovieGenderEmbeddingDenseModelFactory.create(\n",
    "        n_users, \n",
    "        n_movies,\n",
    "        n_genders           = len(GENDER_COLUMNS),\n",
    "        min_rating          = min_rating,\n",
    "        max_rating          = max_rating,\n",
    "        user_n_min_factors  = user_embeding_vector_size,\n",
    "        movie_n_min_factors = movie_embeding_vector_size,\n",
    "        lr                  = lr,\n",
    "        units               = [units1,   units2,   units3],\n",
    "        dropout             = [dropout1, dropout2, dropout3]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search best model hyper parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Create an optimizer to search bestmodel hyper aprams give a set of optimmmmmizer hyperparams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 9\n",
      "lr (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.001], 'ordered': True}\n",
      "units1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 300, 'step': 10, 'sampling': None}\n",
      "dropout1 (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.9, 'step': 0.1, 'sampling': None}\n",
      "units2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 300, 'step': 10, 'sampling': None}\n",
      "dropout2 (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.9, 'step': 0.1, 'sampling': None}\n",
      "units3 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 300, 'step': 10, 'sampling': None}\n",
      "dropout3 (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.9, 'step': 0.1, 'sampling': None}\n",
      "usersfactor (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 50, 'max_value': 500, 'step': 50, 'sampling': None}\n",
      "moviesfactor (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 50, 'max_value': 500, 'step': 50, 'sampling': None}\n"
     ]
    }
   ],
   "source": [
    "path = create_path('./tunes')\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    model_builder,\n",
    "    objective    = 'val_loss',\n",
    "    max_epochs   = 200,\n",
    "    factor       = 3,\n",
    "    directory    = path,\n",
    "    project_name = 'recommendations'\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 204 Complete [00h 00m 21s]\n",
      "val_loss: 0.7575242519378662\n",
      "\n",
      "Best val_loss So Far: 0.7301939725875854\n",
      "Total elapsed time: 00h 30m 15s\n",
      "\n",
      "Search: Running Trial #205\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "lr                |0.001             |0.001             \n",
      "units1            |150               |250               \n",
      "dropout1          |0.4               |0.7               \n",
      "units2            |220               |20                \n",
      "dropout2          |0.3               |0.6               \n",
      "units3            |50                |100               \n",
      "dropout3          |0.6               |0.5               \n",
      "usersfactor       |300               |300               \n",
      "moviesfactor      |100               |100               \n",
      "tuner/epochs      |67                |23                \n",
      "tuner/initial_e...|23                |8                 \n",
      "tuner/bracket     |3                 |3                 \n",
      "tuner/round       |2                 |1                 \n",
      "tuner/trial_id    |5f7241debf711da...|350108a097934de...\n",
      "\n",
      "Epoch 24/67\n",
      "100/100 [==============================] - 2s 13ms/step - loss: 0.9733 - val_loss: 0.7738\n",
      "Epoch 25/67\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.7245 - val_loss: 0.7585\n",
      "Epoch 26/67\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 0.6811 - val_loss: 0.7488\n",
      "Epoch 27/67\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.6518 - val_loss: 0.7386\n",
      "Epoch 28/67\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 0.6465"
     ]
    }
   ],
   "source": [
    "tuner.search(\n",
    "    train_generator,\n",
    "    validation_data     = val_generator,\n",
    "    callbacks           = [EarlyStopping(monitor='val_loss', patience=8)],\n",
    "    use_multiprocessing = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Show best model hyperparameters give a set of optimizer hyperparams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a summary of the search\n",
    "tuner.results_summary(num_trials=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: Get best model founded by the optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate best model on train validation an test sets to see loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(best_model, train_set, batch_size=train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(best_model, val_set, batch_size=val_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(best_model, test_set, batch_size=val_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "* Loss under train set of greater than evalidation set. This good a signal.\n",
    "* Loss under evaliadtion an test sets if pratically the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Create model with best founded hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_best_model_from(tuner) \n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Train model under train set only and plot train vs validation loss by epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = get_best_hyperparameters(tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=50,\n",
    "    callbacks=[\n",
    "        create_metrics_callback(), \n",
    "        create_checkpoints_callback(),\n",
    "        EarlyStopping(monitor='val_loss', patience=5)\n",
    "    ],\n",
    "    use_multiprocessing=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: Evaluate model under train, validaiton an test set to see loss diferences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, train_set, batch_size=train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, val_set, batch_size=val_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, test_set, batch_size=val_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "* Again, loss under train set is greater than evalidation set. This good a signal.\n",
    "* Loss under evaluation set is less thant test sets, this is normal. Because test set have never been seen by the model but evalidation set was used to optimize the model.\n",
    "* Tran vs validation loss are very close each other, is a good signal. In principle, there is no overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4**: Now we search epoch with lowest loss value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_per_epoch = history.history['val_loss']\n",
    "plot_loss(val_loss_per_epoch)\n",
    "\n",
    "epochs = lowest_loss_epoch(val_loss_per_epoch)\n",
    "logging.info(f'Lowest loss epoch: {epochs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5**: Re train best model trainig only with lowest loss epoch value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_best_model_from(tuner)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=epochs,\n",
    "    callbacks=[\n",
    "        create_metrics_callback(), \n",
    "        create_checkpoints_callback(),\n",
    "        EarlyStopping(monitor='val_loss', patience=5)\n",
    "    ],\n",
    "    use_multiprocessing=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, train_set, batch_size=train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, val_set, batch_size=val_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, test_set, batch_size=val_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "* In this cause we found a model with less loss under test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check rating prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict ratings used to train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_set)\n",
    "val_dataset   = Dataset(val_set)\n",
    "test_dataset  = Dataset(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn  = lambda y_pred, y_true: abs(y_pred - y_true)\n",
    "max_error = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = get_metrics(train_dataset, max_error=max_error)\n",
    "\n",
    "{k: train_metrics[k] for k in ('true_positives', 'false_positives')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metrics = get_metrics(val_dataset, max_error=max_error)\n",
    "\n",
    "{k: val_metrics[k] for k in ('true_positives', 'false_positives')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = get_metrics(test_dataset, max_error=max_error)\n",
    "\n",
    "{k: test_metrics[k] for k in ('true_positives', 'false_positives')}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
